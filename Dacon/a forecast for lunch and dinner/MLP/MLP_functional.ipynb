{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 명목형 / 숫자형 나누어서 계산해보기"
      ],
      "metadata": {
        "id": "2vPZGJoT38dW"
      },
      "id": "2vPZGJoT38dW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 요일을 one_hot_encoding으로\n",
        "    # functional 왼쪽 오른쪽으로 나누어서 진행\n",
        "    # val_loss < loss 보다 작으므로 과적함 => 그러려면 층을 줄여주고 노드수도 줄여주는게 좋다\n",
        "    \n",
        "    # 지수러닝으로 줄여줬다 loss < val_loss 보다 (점심 , 저녁 둘다)\n",
        "\n",
        "\n",
        "# Next\n",
        "# 음식들도 가중치가 있는 값으로 변경후에 진행해보기\n",
        "    # 시작"
      ],
      "metadata": {
        "id": "VBD1AVTgN_NU"
      },
      "id": "VBD1AVTgN_NU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EGXxn7T8OIyr"
      },
      "id": "EGXxn7T8OIyr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xLBgZm_2OI4S"
      },
      "id": "xLBgZm_2OI4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S1NoNOcG7DJ4"
      },
      "id": "S1NoNOcG7DJ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XFziaf3_StoL"
      },
      "id": "XFziaf3_StoL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "b-ccKIkiSwMn"
      },
      "id": "b-ccKIkiSwMn"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CpaqnzhSv8Z",
        "outputId": "fa02a86b-2a91-4594-84d6-a937ebefee71"
      },
      "id": "9CpaqnzhSv8Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ln = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/식수인원_MLP_DNN/train_one_hot.csv')\n",
        "\n",
        "test_ln = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/식수인원_MLP_DNN/test_one_hot.csv')"
      ],
      "metadata": {
        "id": "nNlI_i8X38fW"
      },
      "id": "nNlI_i8X38fW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ln.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwFqiT4o389-",
        "outputId": "2e560695-8eda-47fa-8783-92aed19b0b02"
      },
      "id": "SwFqiT4o389-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['numbers', 'dayoff', 'work', 'outsidework', 'workfhome', 'lunch_t',\n",
              "       'dinner_t', 'Month', 'Date', 'bob', 'soup', 'main', 'bobd', 'soupd',\n",
              "       'maind', 'present', 'day_금', 'day_목', 'day_수', 'day_월', 'day_화'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_lunch = test_ln[['numbers', 'dayoff', 'work', 'outsidework', 'workfhome',\n",
        "       'Month', 'Date', 'bob', 'soup', 'main','present','day_금', 'day_목', 'day_수', 'day_월', 'day_화' ]]"
      ],
      "metadata": {
        "id": "9q9xMP0BPfN_"
      },
      "id": "9q9xMP0BPfN_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dinner = test_ln[['numbers', 'dayoff', 'work', 'outsidework', 'workfhome',\n",
        "       'Month', 'Date', 'bobd', 'soupd', 'maind','present', 'day_금', 'day_목', 'day_수', 'day_월', 'day_화']]"
      ],
      "metadata": {
        "id": "tsqW3UYYPfSK"
      },
      "id": "tsqW3UYYPfSK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_ln = [['day','bob','soup','main','present','lunch_t']]\n",
        "# X_test = [['day','bob','soup','main','present']]"
      ],
      "metadata": {
        "id": "9wYMzPpx3-w2"
      },
      "id": "9wYMzPpx3-w2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_ln[['numbers', 'dayoff', 'work', 'outsidework', 'workfhome',\n",
        "       'Month', 'Date', 'bob', 'soup', 'main','present', 'day_금', 'day_목', 'day_수', 'day_월', 'day_화']]\n",
        "y = train_ln['lunch_t']"
      ],
      "metadata": {
        "id": "-pV9-Wiz4ulS"
      },
      "id": "-pV9-Wiz4ulS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_vali, y_train, y_vali = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "\n",
        "                                                    shuffle=True, \n",
        "\n",
        "                                                    random_state=1004)\n"
      ],
      "metadata": {
        "id": "3wHxUc5EBjuA"
      },
      "id": "3wHxUc5EBjuA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qi0UHe6NZzx7"
      },
      "id": "Qi0UHe6NZzx7"
    },
    {
      "cell_type": "code",
      "source": [
        "def model_dnn(Nin, Nh, Nh1, Nout):\n",
        "    x = keras.layers.Input(shape=(Nin,)) \n",
        "\n",
        "    b = keras.layers.BatchNormalization()(x)\n",
        "    h1 = keras.layers.Activation('elu')(keras.layers.Dense(Nh, kernel_initializer = 'he_normal')(b))\n",
        "    h1 = keras.layers.Activation('elu')(keras.layers.Dense(Nh, kernel_initializer = 'he_normal')(b))\n",
        "    h1 = keras.layers.Activation('elu')(keras.layers.Dense(Nh, kernel_initializer = 'he_normal')(b))\n",
        "    h = keras.layers.Activation('elu')(keras.layers.Dense(Nh, kernel_initializer = 'he_normal')(h1))\n",
        "    b1 = keras.layers.BatchNormalization()(h)\n",
        "\n",
        "\n",
        "    b2 = keras.layers.BatchNormalization()(x)\n",
        "    h2 = keras.layers.Activation('elu')(keras.layers.Dense(Nh1, kernel_initializer = 'he_normal')(b2))\n",
        "    b2 = keras.layers.Activation('elu')(keras.layers.Dense(Nh1, kernel_initializer = 'he_normal')(h2))\n",
        "    b2 = keras.layers.Dropout(rate=0.3)(b2)\n",
        "    \n",
        "\n",
        "    merge = keras.layers.concatenate([b1, b2])\n",
        "    merge = keras.layers.Dropout(rate=0.2)(merge)\n",
        "    merge = keras.layers.BatchNormalization()(merge)\n",
        "\n",
        "\n",
        "    y = keras.layers.Dense(Nout)(merge)\n",
        "    model = keras.models.Model(x, y) \n",
        "    model.compile(loss='mae', optimizer='nadam') \n",
        "    \n",
        "    return model \n"
      ],
      "metadata": {
        "id": "MK8ixx-iEUK2"
      },
      "id": "MK8ixx-iEUK2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_dnn(X_train.shape[1], 50, 100, 1)"
      ],
      "metadata": {
        "id": "1bpReKisE0Ju"
      },
      "id": "1bpReKisE0Ju",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H94zzaBqJWj8",
        "outputId": "bf9fabe1-0acb-4f07-dd3b-fb975135c2c0"
      },
      "id": "H94zzaBqJWj8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)          [(None, 16)]         0           []                               \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 16)          64          ['input_27[0][0]']               \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 16)          64          ['input_27[0][0]']               \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_166 (Dense)              (None, 50)           850         ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " dense_168 (Dense)              (None, 100)          1700        ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 50)           0           ['dense_166[0][0]']              \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 100)          0           ['dense_168[0][0]']              \n",
            "                                                                                                  \n",
            " dense_167 (Dense)              (None, 50)           2550        ['activation_142[0][0]']         \n",
            "                                                                                                  \n",
            " dense_169 (Dense)              (None, 100)          10100       ['activation_144[0][0]']         \n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 50)           0           ['dense_167[0][0]']              \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 100)          0           ['dense_169[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 50)          200         ['activation_143[0][0]']         \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)           (None, 100)          0           ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 150)          0           ['batch_normalization_106[0][0]',\n",
            "                                                                  'dropout_53[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_54 (Dropout)           (None, 150)          0           ['concatenate_24[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 150)         600         ['dropout_54[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_170 (Dense)              (None, 1)            151         ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,279\n",
            "Trainable params: 15,815\n",
            "Non-trainable params: 464\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.0001, s=20)"
      ],
      "metadata": {
        "id": "cK5ZsnnmMbl1"
      },
      "id": "cK5ZsnnmMbl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_vali, y_vali),\n",
        "                    epochs=1000, verbose=1, batch_size=32, callbacks = [early_stopping_cb, lr_scheduler] )"
      ],
      "metadata": {
        "id": "fbyoXOSxK5-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c71e59-289f-470c-e164-9ffdae947bad"
      },
      "id": "fbyoXOSxK5-T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 47.9058 - val_loss: 52.4120 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 50.8922 - val_loss: 52.5134 - lr: 8.9125e-05\n",
            "Epoch 3/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.8354 - val_loss: 52.4651 - lr: 7.9433e-05\n",
            "Epoch 4/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.2782 - val_loss: 52.3057 - lr: 7.0795e-05\n",
            "Epoch 5/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.6567 - val_loss: 52.2943 - lr: 6.3096e-05\n",
            "Epoch 6/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 50.7510 - val_loss: 52.2487 - lr: 5.6234e-05\n",
            "Epoch 7/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.4013 - val_loss: 52.3559 - lr: 5.0119e-05\n",
            "Epoch 8/1000\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 47.6664 - val_loss: 52.3723 - lr: 4.4668e-05\n",
            "Epoch 9/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 51.6614 - val_loss: 52.4232 - lr: 3.9811e-05\n",
            "Epoch 10/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.9982 - val_loss: 52.4514 - lr: 3.5481e-05\n",
            "Epoch 11/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.1491 - val_loss: 52.2542 - lr: 3.1623e-05\n",
            "Epoch 12/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.3418 - val_loss: 52.1805 - lr: 2.8184e-05\n",
            "Epoch 13/1000\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 47.6425 - val_loss: 52.0941 - lr: 2.5119e-05\n",
            "Epoch 14/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.1305 - val_loss: 52.2183 - lr: 2.2387e-05\n",
            "Epoch 15/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.0758 - val_loss: 52.2434 - lr: 1.9953e-05\n",
            "Epoch 16/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 46.9198 - val_loss: 52.2100 - lr: 1.7783e-05\n",
            "Epoch 17/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.3259 - val_loss: 52.1400 - lr: 1.5849e-05\n",
            "Epoch 18/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.7371 - val_loss: 52.2314 - lr: 1.4125e-05\n",
            "Epoch 19/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.3061 - val_loss: 52.3764 - lr: 1.2589e-05\n",
            "Epoch 20/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.5054 - val_loss: 52.4241 - lr: 1.1220e-05\n",
            "Epoch 21/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.8106 - val_loss: 52.4112 - lr: 1.0000e-05\n",
            "Epoch 22/1000\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 48.3059 - val_loss: 52.3777 - lr: 8.9125e-06\n",
            "Epoch 23/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.3084 - val_loss: 52.2701 - lr: 7.9433e-06\n",
            "Epoch 24/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 48.2063 - val_loss: 52.2595 - lr: 7.0795e-06\n",
            "Epoch 25/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.5755 - val_loss: 52.3334 - lr: 6.3096e-06\n",
            "Epoch 26/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.5093 - val_loss: 52.2648 - lr: 5.6234e-06\n",
            "Epoch 27/1000\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 49.3946 - val_loss: 52.2632 - lr: 5.0119e-06\n",
            "Epoch 28/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.2034 - val_loss: 52.2159 - lr: 4.4668e-06\n",
            "Epoch 29/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 46.7020 - val_loss: 52.2142 - lr: 3.9811e-06\n",
            "Epoch 30/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 50.3733 - val_loss: 52.2878 - lr: 3.5481e-06\n",
            "Epoch 31/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 46.6472 - val_loss: 52.2535 - lr: 3.1623e-06\n",
            "Epoch 32/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 46.5203 - val_loss: 52.3769 - lr: 2.8184e-06\n",
            "Epoch 33/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.7366 - val_loss: 52.2586 - lr: 2.5119e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss > val_loss => 과대적합이 아닌가..?"
      ],
      "metadata": {
        "id": "UKZr4gNmwA7o"
      },
      "id": "UKZr4gNmwA7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "\n",
        "lunch = model.predict(test_lunch)"
      ],
      "metadata": {
        "id": "w2hn7tPlMvUC"
      },
      "id": "w2hn7tPlMvUC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/식수인원_MLP_DNN/sample_submission.csv')\n",
        "submit['중식계'] = lunch"
      ],
      "metadata": {
        "id": "YRrEW4ZGPxiJ"
      },
      "id": "YRrEW4ZGPxiJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JfyqjezvQWxh"
      },
      "id": "JfyqjezvQWxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저녁\n",
        "X = train_ln[[ 'numbers', 'dayoff', 'work', 'outsidework', 'workfhome',\n",
        "       'Month', 'Date', 'bobd', 'soupd', 'maind','present', 'day_금', 'day_목', 'day_수', 'day_월', 'day_화']]\n",
        "y = train_ln['dinner_t']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_vali, y_train, y_vali = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "\n",
        "                                                    shuffle=True, \n",
        "\n",
        "                                                    random_state=1004)\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_vali, y_vali),\n",
        "                    epochs=1000, verbose=1, batch_size=32, callbacks = [early_stopping_cb, lr_scheduler] )\n",
        "\n",
        "dinner = model.predict(test_dinner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVC0p1h2QWzp",
        "outputId": "08194b45-a08d-4b37-d0c8-2cec6cdb2d84"
      },
      "id": "qVC0p1h2QWzp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 47.5575 - val_loss: 52.5636 - lr: 1.0000e-04\n",
            "Epoch 2/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.0481 - val_loss: 52.6040 - lr: 8.9125e-05\n",
            "Epoch 3/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 47.6325 - val_loss: 52.4458 - lr: 7.9433e-05\n",
            "Epoch 4/1000\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 47.7413 - val_loss: 52.4277 - lr: 7.0795e-05\n",
            "Epoch 5/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.5310 - val_loss: 52.5565 - lr: 6.3096e-05\n",
            "Epoch 6/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 47.7375 - val_loss: 52.5253 - lr: 5.6234e-05\n",
            "Epoch 7/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.8860 - val_loss: 52.5152 - lr: 5.0119e-05\n",
            "Epoch 8/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 48.2025 - val_loss: 52.4601 - lr: 4.4668e-05\n",
            "Epoch 9/1000\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 49.2436 - val_loss: 52.4602 - lr: 3.9811e-05\n",
            "Epoch 10/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 47.6100 - val_loss: 52.3286 - lr: 3.5481e-05\n",
            "Epoch 11/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.9646 - val_loss: 52.3872 - lr: 3.1623e-05\n",
            "Epoch 12/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.0659 - val_loss: 52.4176 - lr: 2.8184e-05\n",
            "Epoch 13/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.6769 - val_loss: 52.4377 - lr: 2.5119e-05\n",
            "Epoch 14/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 47.8921 - val_loss: 52.3246 - lr: 2.2387e-05\n",
            "Epoch 15/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 47.0676 - val_loss: 52.3418 - lr: 1.9953e-05\n",
            "Epoch 16/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 47.7336 - val_loss: 52.2875 - lr: 1.7783e-05\n",
            "Epoch 17/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 48.9338 - val_loss: 52.3730 - lr: 1.5849e-05\n",
            "Epoch 18/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.9205 - val_loss: 52.4161 - lr: 1.4125e-05\n",
            "Epoch 19/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.8103 - val_loss: 52.3465 - lr: 1.2589e-05\n",
            "Epoch 20/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.4517 - val_loss: 52.2488 - lr: 1.1220e-05\n",
            "Epoch 21/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 47.1492 - val_loss: 52.2533 - lr: 1.0000e-05\n",
            "Epoch 22/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.4024 - val_loss: 52.3545 - lr: 8.9125e-06\n",
            "Epoch 23/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.1232 - val_loss: 52.3891 - lr: 7.9433e-06\n",
            "Epoch 24/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 48.5161 - val_loss: 52.4092 - lr: 7.0795e-06\n",
            "Epoch 25/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 47.2546 - val_loss: 52.3984 - lr: 6.3096e-06\n",
            "Epoch 26/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 49.1684 - val_loss: 52.3019 - lr: 5.6234e-06\n",
            "Epoch 27/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 51.2439 - val_loss: 52.4304 - lr: 5.0119e-06\n",
            "Epoch 28/1000\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 47.4155 - val_loss: 52.4878 - lr: 4.4668e-06\n",
            "Epoch 29/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 48.3860 - val_loss: 52.3592 - lr: 3.9811e-06\n",
            "Epoch 30/1000\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 46.5744 - val_loss: 52.3601 - lr: 3.5481e-06\n",
            "Epoch 31/1000\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 48.7873 - val_loss: 52.4587 - lr: 3.1623e-06\n",
            "Epoch 32/1000\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 47.1178 - val_loss: 52.4552 - lr: 2.8184e-06\n",
            "Epoch 33/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.3168 - val_loss: 52.4911 - lr: 2.5119e-06\n",
            "Epoch 34/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.5019 - val_loss: 52.4123 - lr: 2.2387e-06\n",
            "Epoch 35/1000\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 49.7602 - val_loss: 52.4378 - lr: 1.9953e-06\n",
            "Epoch 36/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.7996 - val_loss: 52.4752 - lr: 1.7783e-06\n",
            "Epoch 37/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 47.8708 - val_loss: 52.4620 - lr: 1.5849e-06\n",
            "Epoch 38/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 45.7018 - val_loss: 52.4449 - lr: 1.4125e-06\n",
            "Epoch 39/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.7599 - val_loss: 52.4707 - lr: 1.2589e-06\n",
            "Epoch 40/1000\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 49.5648 - val_loss: 52.5726 - lr: 1.1220e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit['석식계'] = dinner"
      ],
      "metadata": {
        "id": "lRtOhnO-QHOp"
      },
      "id": "lRtOhnO-QHOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('Dnn_functional_05_one_hot_day.csv', index=False)"
      ],
      "metadata": {
        "id": "Xcik3zX0ROkw"
      },
      "id": "Xcik3zX0ROkw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DpdqDvFWRPmA"
      },
      "id": "DpdqDvFWRPmA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 요일을 원핫인코딩으로 준뒤에 학습\n",
        "    - functional 방식으로 오른쪽 왼쪽을 다르게 주고 학습을 진행했다\n",
        "    - 점신에서는 loss > loss_val 여서 과적합이 라고 생각\n",
        "    - 하지만 저녁에서는 loss < loss_val 작으므로 이거는 잘나왔다생각\n",
        "\n",
        "### 결과\n",
        "- train : 352.813621\n",
        "- test : 358.2780774286\n",
        "\n"
      ],
      "metadata": {
        "id": "pwooyosINd7U"
      },
      "id": "pwooyosINd7U"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "beTJzXw8NjNs"
      },
      "id": "beTJzXw8NjNs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "코드리뷰_09.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}